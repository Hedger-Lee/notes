### 面试要点：

数据库优化

​		Oracle数据库优化

1. 首先查看表格的数据量，数据量如果超过了2000W就一定要去给表格设置分区
2. 表格中的索引是否合理（表格一定要有主键，索引的数量（大表索引不能超过5个，小表索引不能超过列数量的15%））
3. sql语句里面有没有导致索引失效的情况
4. 如果要做联合查询，先筛选数据，然后对筛选后的结果做表连接
5. 如果表的数据量特别大，然后又需要做表连接，就需要将筛选结果存入到临时表，然后用临时表进行表连接
6. where查询的顺序，数据筛选量大的放在右边，筛选量小的放在左边
7. 尽量先用where筛选然后再分组，having只对聚合结果筛选
8. 尽量不要用select * from 表
9. 尽量使用decode()去替代case when，函数计算效率更高
10. 使用union all替代or，union all是并行
11. 使用group by 替代distinct，分组比以行为单位筛选更快
12. 使用大写的sql替代小写的sql，数据库本来就是要转换成大写再运行的
13. 尽量少使用union minus intersect这三种集合运算，这三种集合会多一步sort unique的排序操作
14. 使用exists()函数去替代in 包含语句

​		Hive数据库优化

数据库倾斜：

1. 表连接查询  大表 和 小表的连接

   第一种方法：mapjoin优化器

   第二种方法：也可以将大表格拆分成多个小表格，和小表连接，最后进行结果的拼接。

2. null值在查询的时候会产生数据倾斜

   concat('null_', rand())

3. count(distinct 字段名)
   group by去重然后用count统计

4. 开关上的优化

   ````
   聚合计算优化开关：set hive.map.aggr=true;
   
   负载均衡开关：set hive.groupby.skewindata=true;
   
   设置每一个reduce处理和计算的数据量大小：
   set hive.exec.reducers.bytes.per.reducer=xxx;
   
   设置启用的reduce的数量：
   set hive.exec.reducers.max=xxx;
   ````

小文件过多的优化



物化视图和视图

​		物化视图

​		视图



存储过程、函数和触发器

​		存储过程

​		函数

​		触发器



数据备份

​		热备份

​		冷备份



项目指标/



BI数据分层

ODS：ODM、SDM

DW：FDM

DM：ADM

DA



维度和粒度



三范式

​		第一范式

​		第二范式

​		第三范式



数据去重

​		使用rowid



聚合函数、单行函数、分析函数

​		聚合函数

​		单行函数

​		分析函数



遇到问题：预期结果和实际结果不符合、

解决：先做数据的抽样检查，例如先拿100条数据等等进行数据的检查；

在每个有逻辑的部分，例如if判断或者循环结构的外面和里面，都对需要的变量进行打印和查看，查询数据在哪个地方偏离的计算。



重跑：

先使用调度工具马上运行一次，检查是否有错误；

如果有错误，使用脚本自己在数据库中去运行一次检查是否有错；

如果还有错误，说明数据表有可能发生了表结构上的修改，这个时候就要修改脚本，然后重新配置调度任务，重新运行检查是否有错误。



使用工具的版本

​		Oracle11g

​		hadoop2.8

​		hive2.1

​		sqoop1.4

​		kettle7.1

​		finereport8.1

用过的工具

分区

​		Oracle中的分区

​		Hive中的分区



索引

​		普通索引

​		主键索引

​		唯一索引

​		组合索引

​		函数索引

​		位图索引

​		分区索引

​				本地索引

​				全局索引

​		索引失效：

