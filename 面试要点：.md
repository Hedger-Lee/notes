### 面试要点：

数据库优化

​		Oracle数据库优化

1. 首先查看表格的数据量，数据量如果超过了2000W就一定要去给表格设置分区
2. 表格中的索引是否合理（表格一定要有主键，索引的数量（大表索引不能超过5个，小表索引不能超过列数量的15%））
3. sql语句里面有没有导致索引失效的情况
4. 如果要做联合查询，先筛选数据，然后对筛选后的结果做表连接
5. 如果表的数据量特别大，然后又需要做表连接，就需要将筛选结果存入到临时表，然后用临时表进行表连接
6. where查询的顺序，数据筛选量大的放在右边，筛选量小的放在左边
7. 尽量先用where筛选然后再分组，having只对聚合结果筛选
8. 尽量不要用select * from 表
9. 尽量使用decode()去替代case when，函数计算效率更高
10. 使用union all替代or，union all是并行
11. 使用group by 替代distinct，分组比以行为单位筛选更快
12. 使用大写的sql替代小写的sql，数据库本来就是要转换成大写再运行的
13. 尽量少使用union minus intersect这三种集合运算，这三种集合会多一步sort unique的排序操作
14. 使用exists()函数去替代in 包含语句

​		Hive数据库优化

数据库倾斜：

1. 表连接查询  大表 和 小表的连接

   第一种方法：mapjoin优化器

   第二种方法：也可以将大表格拆分成多个小表格，和小表连接，最后进行结果的拼接。

2. null值在查询的时候会产生数据倾斜

   concat('null_', rand())

3. count(distinct 字段名)
   group by去重然后用count统计

4. 开关上的优化

   ````
   聚合计算优化开关：set hive.map.aggr=true;
   
   负载均衡开关：set hive.groupby.skewindata=true;
   
   设置每一个reduce处理和计算的数据量大小：
   set hive.exec.reducers.bytes.per.reducer=xxx;
   
   设置启用的reduce的数量：
   set hive.exec.reducers.max=xxx;
   ````

小文件过多的优化

**小文件从哪里来的？**

> 分区分桶会得到很多的小文件；

> 数据源本身就有很多小文件；

> reduce数量过多的时候。

**小文件过多的时候，为什么会影响到服务器性能？**

影响：

> 每一个文件，都需要一个jvm的进程去处理和执行，会造成资源的浪费，影响执行的效率；

> hdfs存储过多小文件，会造成硬盘资源的浪费。

**怎么调整和优化？**

1. 不要使用textfile存储数据

2. 通过开关来调节：

```
控制每个map端拆分数据的最大值大小：每个mapper可以拆分多大的数据
set mapred.max.split.size=xxx;

控制每一个处理数据节点的处理数据大小：每个mapper可以处理多大的数据
set mapred.min.split.size.per.node=xxx;

设置的合并的map端输出的数据：
set hive.merge.mapfiles=true;

设置的合并的reduce端输出的数据：
set hive.merge.mapredfiles=true;

设置合并后的数据的大小：低于该值就会合并
set hive.merge.size.per.task=xxx;

需要被合并的文件大小：低于这个值就需要合并
set hive.merge.smallfiles.avgsize=xxx;
```





物化视图和视图

​		物化视图

​		视图

1. 简化日常操作，将很长的sql语句简化成一个单词的名字
2. 简化业务，将其他部门需要列显示出来即可
3. 安全性更高，可以隐藏关键和敏感的字段，加上只读之后无法修改原表的数据
4. 节省网络流量



存储过程、函数和触发器

​		存储过程

​		函数

​		触发器



数据备份

​		热备份

​		冷备份



项目指标/



BI数据分层

ODS：ODM、SDM

DW：FDM

DM：ADM

DA



维度和粒度



三范式

​		第一范式

​		第二范式

​		第三范式



数据去重

​		使用rowid



聚合函数、单行函数、分析函数

​		聚合函数

​		单行函数

​		分析函数



遇到问题：预期结果和实际结果不符合、

解决：先做数据的抽样检查，例如先拿100条数据等等进行数据的检查；

在每个有逻辑的部分，例如if判断或者循环结构的外面和里面，都对需要的变量进行打印和查看，查询数据在哪个地方偏离的计算。



重跑：

先使用调度工具马上运行一次，检查是否有错误；

如果有错误，使用脚本自己在数据库中去运行一次检查是否有错；

如果还有错误，说明数据表有可能发生了表结构上的修改，这个时候就要修改脚本，然后重新配置调度任务，重新运行检查是否有错误。



使用工具的版本

​		Oracle11g

​		hadoop2.8

​		hive2.1

​		sqoop1.4

​		kettle7.1

​		finereport8.1

用过的工具

分区

​		Oracle中的分区

​		Hive中的分区



索引

​		普通索引

​		主键索引

​		唯一索引

​		组合索引

​		函数索引

​		位图索引

​		分区索引

​				本地索引

​				全局索引

​		索引失效：











<hr/>

<hr/>

hive数据库的优化：
1、少用count,distinct
2、合理使用union all
3、在做表join,先过滤掉不需要的数据
4、小表放前，大表放后
5、把大表拆分多个小表，和小表连接，最后进行结果拼接

数据倾斜的优化：
数据倾斜的表面现象，reduce卡在99%，无法结束任务
1.表连接查询  大表 和 小表的连接
mapjoin优化器
查看mapjoin的开关有没有打开：set hive.auto.convert.join=true;
select /*+ mapjoin(res_dept_zx) */ * from res_emp_zx a join res_dept_zx b on a.deptno=b.deptno;
也可以将大表格拆分成多个小表格，和小表连接，最后进行结果的拼接。
2.null值在查询的时候会产生数据倾斜
concat('null_', rand())

3.count(distinct 字段名)
group by去重然后用count统计
4.开关上的优化
聚合计算优化开关：set hive.map.aggr=true;
负载均衡开关：set hive.groupby.skewindata=true;
设置每一个reduce处理和计算的数据量大小：
set hive.exec.reducers.bytes.per.reducer=xxx;
设置启用的reduce的数量：
set hive.exec.reducers.max=xxx;
小文件过多的优化：
小文件从哪里来的？
分区分桶会得到很多的小文件；
数据源本身就有很多小文件；
reduce数量过多的时候。
影响：
每一个文件，都需要一个jvm的进程去处理和执行，会造成资源的浪费，影响执行的效率；
hdfs存储过多小文件，会造成硬盘资源的浪费。
怎么调整和优化？
1.不要使用textfile存储数据
2.通过开关来调节：
控制每个map端拆分数据的最大值大小：
set mapred.max.split.size=xxx;
控制每一个处理数据节点的处理数据大小：
set mapred.min.split.size.per.node=xxx;
设置的合并的map端输出的数据：
set hive.merge.mapfiles=true;
设置的合并的reduce端输出的数据：
set hive.merge.mapredfiles=true;
设置合并数据的大小：
set hive.merge.size.per.task=xxx;
需要被合并的文件大小：
set hive.merge.smallfiles.avgsize=xxx;

这是之前总结的一些面试需要准备的内容，你可以参考一下
1、熟悉ORACLE常用的表、表结构、索引、视图、存储过程、函数等等。
2、注重ORACLE、MYSQL的SQL编写能力，可以准备两、三个重要开发案例。
2、SQL调优方面，准备常规调优方法。“执行计划”的基础操作、如何查看、如何优化、经典案例分享，可以准备一、两个案例，
3、了解HADOOP原理和架构、有HIVESQL开发经验优先考虑。（项目中主要用HIVESQL开发，第二点和第三点熟练度，二选一。）
4、HIVESQL方面的调优，准备一、两个案例，

1、自我介绍
2、介绍项目
3、你主要负责的工作
4、如果你一段sql语句出现问题，你会怎么解决？
5、你对业务方面熟悉吗？
我在回答5的时候，说到了指标，
6、他就让我具体说一两个指标
7、接着就问数据处理用的什么工具？ 我用的存储过程
8、索引怎么用？哪些不要使用索引？
9、聚合函数有哪些？
10、逾期率怎么算？
11、merge into有用过吗？
12、你有什么问题想要问我的？

2、数据仓库，数据集市一般用哪几种建模方式？

金证一面：
Hive 写过吗？
Hadoop了解吗？
用的数据库主要是哪个？
Sql优化怎么优化？
BI主要用在哪一块？

招商证券（外包）      1.A表有1行数据，B表有2行数据。什么情况下会等于0条数据，1条数据，2条数据。
2.A库和B库的跨库查询
3.存储过程里，如果用insert.delete.update 要写几个commit
4.live bos有没有用过
5.存储过程写了哪些
6.存储过程错误会有日志吗？
7.ERWIN建表建过多少次，建多少个表，有多少个通用字段？例如？  8.什么是事物  9.索引失效条件   

Sqoop的优点是什么？
同义词是什么？为什么要用同义词？只是取别名干嘛不直接在表后面取别名？
增量抽取和全量抽取是怎么区别的？增量抽取多久做一次？数据有多少？
分析函数除了over窗口函数还用过别的什么函数？
项目中什么情况下要用分区表？怎么用？

Mapjoin优化大小表join产生的数据倾斜原理：
大小表join为何会产生数据倾斜